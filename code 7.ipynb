{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pickle\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "   \n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "\n",
    "\n",
    "image_x, image_y = 50, 50\n",
    "with open(\"test_images\", \"rb\") as f:\n",
    "\ttest_images = np.array(pickle.load(f))\n",
    "with open(\"test_labels\", \"rb\") as f:\n",
    "\ttest_labels = np.array(pickle.load(f), dtype=np.int32)\n",
    "test_images = np.reshape(test_images, (test_images.shape[0], image_x, image_y, 1))\n",
    "\n",
    "\n",
    "model = load_model('cnn_model_keras2.h5')\n",
    "pred_labels = []\n",
    "\n",
    "start_time = time.time()\n",
    "pred_probabs = model.predict(test_images)\n",
    "end_time = time.time()\n",
    "pred_time = end_time-start_time\n",
    "avg_pred_time = pred_time/test_images.shape[0]\n",
    "print(\"Time taken to predict %d test images is %ds\" %(test_images.shape[0], pred_time))\n",
    "print('Average prediction time: %fs' % (avg_pred_time))\n",
    "\n",
    "for pred_probab in pred_probabs:\n",
    "\tpred_labels.append(list(pred_probab).index(max(pred_probab)))\n",
    "\n",
    "cm = confusion_matrix(test_labels, np.array(pred_labels))\n",
    "classification_report = classification_report(test_labels, np.array(pred_labels))\n",
    "print('\\n\\nClassification Report') \n",
    "print('---------------------------')\n",
    "print(classification_report)\n",
    "plot_confusion_matrix(cm, range(44), normalize=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
